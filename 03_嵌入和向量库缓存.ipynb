{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 嵌入和向量库缓存\n",
    "\n",
    "![image.png](imgs/RAG.png)\n",
    "\n",
    "在上节中我们成功将文本拆分为合适大小的块，本节我们要将文本块用于嵌入模型，并生成嵌入向量。本节对应上图的5、6、7。\n",
    "\n",
    "**嵌入(Embedding)的含义**\n",
    "\n",
    "![图像来自网络](imgs/Word2vec.png)\n",
    "\n",
    "langchain官方的描述是这样：\n",
    "> Embedding Models take a piece of text and create a numerical representation of it.\n",
    "> \n",
    ">嵌入模型获取一段文本，并创建它的数字表示。\n",
    "\n",
    "嵌入可以理解为**向量化**，例如将文本、图像、音频等数据转换为向量。这样做的本质是**将样本映射到了高维的向量空间**，这个向量空间具有很多适应机器学习算法的性质。比如文本向量化之后可以进行距离度量(代表语义相近程度)。\n",
    "\n",
    "![图像来自网络](imgs/Word_Embedding.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们先定义好一个Embedding模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import XinferenceEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "# 首先定义一个embedding模型(这里是基于xinference的)\n",
    "server_url=os.environ.get(\"SERVER_URL\")\n",
    "model_uid=os.environ.get(\"EMBEDDING_MODEL_UID\")\n",
    "embeddings_model = XinferenceEmbeddings(\n",
    "    server_url=server_url,\n",
    "    model_uid=model_uid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`langchain`的`Embedding`基类中提供了两种方法，一种用于嵌入文档，另一种用于嵌入查询。前者为`.embed_documents`，它接收多个文本作为输入，且返回多个浮点数列表；而后者`.embed_query`接收单个文本，且返回一个浮点数列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1024)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 嵌入文档\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi there!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"What's your name?\",\n",
    "        \"My friends call me World\",\n",
    "        \"Hello World!\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006304293405264616,\n",
       " 0.011977086775004864,\n",
       " -0.025325916707515717,\n",
       " -0.02862994372844696,\n",
       " 0.0062356023117899895]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 嵌入查询\n",
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "embedded_query[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了避免重复计算，embedd可以做缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5231650d-e76a-58ee-bae4-0efd08f4f3a6',\n",
       " 'd27bc52d-cc17-5467-ac2e-258b752a4ba9']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.storage import InMemoryStore, LocalFileStore\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "fs = LocalFileStore(\"./cache/\")\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings_model, fs, namespace=embeddings_model.model_uid\n",
    ")\n",
    "\n",
    "#缓存在嵌入之前为空\n",
    "list(fs.yield_keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一次用时：0.09300374984741211\n",
      "第二次用时：0.0009961128234863281\n"
     ]
    }
   ],
   "source": [
    "# 加载一个文档并分割它（还记的上一节的内容吗）\n",
    "raw_documents = TextLoader(\"data/index.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)  # 文本版本\n",
    "documents = text_splitter.split_documents(raw_documents)  # 文档版本\n",
    "\n",
    "# 创建矢量存储\n",
    "from time import time\n",
    "start = time()\n",
    "db = FAISS.from_documents(documents, cached_embedder)\n",
    "print(f'第一次用时：{time() - start}')\n",
    "\n",
    "# 再次创建时会快得多，因为在缓存中无需计算embedd。\n",
    "start = time()\n",
    "db = FAISS.from_documents(documents, cached_embedder)\n",
    "print(f'第二次用时：{time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5231650d-e76a-58ee-bae4-0efd08f4f3a6',\n",
       " 'bge-large-zh-v1.55231650d-e76a-58ee-bae4-0efd08f4f3a6',\n",
       " 'bge-large-zh-v1.5d27bc52d-cc17-5467-ac2e-258b752a4ba9',\n",
       " 'd27bc52d-cc17-5467-ac2e-258b752a4ba9']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#缓存中出现内容\n",
    "list(fs.yield_keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一次用时：0.06074833869934082\n",
      "第二次用时：0.0\n"
     ]
    }
   ],
   "source": [
    "#在内存中\n",
    "store = InMemoryStore()\n",
    "underlying_embeddings = embeddings_model\n",
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings, store, namespace=embeddings_model.model_uid\n",
    ")\n",
    "\n",
    "start = time()\n",
    "embeddings = embedder.embed_documents([\"hello\", \"goodbye\"])\n",
    "print(f\"第一次用时：{time()-start}\")\n",
    "\n",
    "start = time()\n",
    "embeddings = embedder.embed_documents([\"hello\", \"goodbye\"])\n",
    "print(f\"第二次用时：{time()-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
